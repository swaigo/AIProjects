{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Retrieval Augmented Generation\n",
    "\n",
    "LLM's excel at a wide range of tasks, but they will struggle with queries specific to a unique business context. This is where Retrieval Augmented Generation (RAG) becomes invaluable. RAG enables an LLM to leverage your internal knowledge bases or customer support documents, significantly enhancing its ability to answer domain-specific questions. Enterprises are increasingly building RAG applications to improve workflows in customer support, Q&A over internal company documents, financial & legal analysis, and much more.\n",
    "\n",
    "This short notebook demonstrate how to create a simple RAG solution using the Anthropic documentation as the source for knowledge base.\n",
    "\n",
    "It creates up a basic RAG system using an in-memory vector database and embeddings from [Voyage AI](https://www.voyageai.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install needed libraries, including:\n",
    "\n",
    "1) `anthropic` - to interact with Claude\n",
    "\n",
    "2) `voyageai` - to generate high quality embeddings\n",
    "\n",
    "3) `pandas`, `numpy` - for data processing\n",
    "\n",
    "\n",
    "You'll also need an `API key` for:\n",
    "[Voyage AI](https://www.voyageai.com/) - for embeddings\n",
    "\n",
    "Optionally, provide an `API key` for Anthropic Cloud Service. If not provided the code will use Amazon Bedrock.\n",
    "For `API key` go to [Anthropic](https://www.anthropic.com/)\n",
    "\n",
    "Note: This code will run with Claude Haiku model unless changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.37.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (0.20.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tokenizers>=0.13.0->anthropic) (0.26.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.2.3)\n",
      "Requirement already satisfied: voyageai in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from voyageai) (3.10.6)\n",
      "Requirement already satisfied: aiolimiter<2.0.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from voyageai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from voyageai) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0,>=2.20 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from voyageai) (2.32.3)\n",
      "Requirement already satisfied: tenacity>=8.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from voyageai) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.5->voyageai) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.5->voyageai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.5->voyageai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.5->voyageai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.5->voyageai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.5->voyageai) (1.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0,>=3.5->voyageai) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.20->voyageai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.20->voyageai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.20->voyageai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.20->voyageai) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp<4.0,>=3.5->voyageai) (4.12.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dotenv in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "## Install the required python packages \n",
    "!pip install anthropic\n",
    "!pip install voyageai\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This notebook requires that at a minimum you have created an account \n",
    "# with VoyageAI (embeddings service) and have set the VOYAGE_API_KEY value in the\n",
    "# file that dotenv is going to read.\n",
    "# See the following for details: https://pypi.org/project/python-dotenv/\n",
    "\n",
    "# load_dotenv() loads in the key value information for the secret keys being used: \n",
    "\n",
    "# 1/ \"VOYAGE_API_KEY\"\n",
    "# 2/ \"ANTHROPIC_API_KEY\" - If you are using the service direct from Anthropic (rather than using Amazon Bedrock)\n",
    "\n",
    "load_dotenv()\n",
    "anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a minimal in-Memory vector DB class\n",
    "\n",
    "In this example, we're using an in-memory vector DB, but for a production application, you may want to use a hosted solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import voyageai\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, name, api_key=None):\n",
    "        if api_key is None:\n",
    "            api_key = os.getenv(\"VOYAGE_API_KEY\")\n",
    "        self.client = voyageai.Client(api_key=api_key)\n",
    "        self.name = name\n",
    "        self.embeddings = []\n",
    "        self.metadata = []\n",
    "        self.query_cache = {}\n",
    "        self.db_path = f\"./data/{name}/vector_db.pkl\"\n",
    "\n",
    "    def load_data(self, data):\n",
    "        if self.embeddings and self.metadata:\n",
    "            print(\"Vector database is already loaded. Skipping data loading.\")\n",
    "            return\n",
    "        if os.path.exists(self.db_path):\n",
    "            print(\"Loading vector database from disk.\")\n",
    "            self.load_db()\n",
    "            return\n",
    "\n",
    "        texts = [f\"Heading: {item['chunk_heading']}\\n\\n Chunk Text:{item['text']}\" for item in data]\n",
    "        self._embed_and_store(texts, data)\n",
    "        self.save_db()\n",
    "        print(\"Vector database loaded and saved.\")\n",
    "\n",
    "    # TODO Change this function to limit text size sent to embeddeding to a max of 256 words\n",
    "    def _embed_and_store(self, texts, data):\n",
    "        batch_size = 128\n",
    "        result = [\n",
    "            self.client.embed(\n",
    "                texts[i : i + batch_size],\n",
    "                model=\"voyage-2\"\n",
    "            ).embeddings\n",
    "            for i in range(0, len(texts), batch_size)\n",
    "        ]\n",
    "        self.embeddings = [embedding for batch in result for embedding in batch]\n",
    "        self.metadata = data\n",
    "\n",
    "    def search(self, query, k=5, similarity_threshold=0.75):\n",
    "        if query in self.query_cache:\n",
    "            query_embedding = self.query_cache[query]\n",
    "        else:\n",
    "            query_embedding = self.client.embed([query], model=\"voyage-2\").embeddings[0]\n",
    "            self.query_cache[query] = query_embedding\n",
    "\n",
    "        if not self.embeddings:\n",
    "            raise ValueError(\"No data loaded in the vector database.\")\n",
    "\n",
    "        similarities = np.dot(self.embeddings, query_embedding)\n",
    "        top_indices = np.argsort(similarities)[::-1]\n",
    "        top_examples = []\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            if similarities[idx] >= similarity_threshold:\n",
    "                example = {\n",
    "                    \"metadata\": self.metadata[idx],\n",
    "                    \"similarity\": similarities[idx],\n",
    "                }\n",
    "                top_examples.append(example)\n",
    "                \n",
    "                if len(top_examples) >= k:\n",
    "                    break\n",
    "        return top_examples\n",
    "\n",
    "    def save_db(self):\n",
    "        data = {\n",
    "            \"embeddings\": self.embeddings,\n",
    "            \"metadata\": self.metadata,\n",
    "            \"query_cache\": json.dumps(self.query_cache),\n",
    "        }\n",
    "        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n",
    "        with open(self.db_path, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_db(self):\n",
    "        if not os.path.exists(self.db_path):\n",
    "            raise ValueError(\"Vector database file not found. Use load_data to create a new database.\")\n",
    "        with open(self.db_path, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        self.embeddings = data[\"embeddings\"]\n",
    "        self.metadata = data[\"metadata\"]\n",
    "        self.query_cache = json.loads(data[\"query_cache\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1 - Basic RAG\n",
    "\n",
    "To get started, we'll set up a basic RAG pipeline using a bare bones approach. This is sometimes called 'Naive RAG' by many in the industry. A basic RAG pipeline includes the following 3 steps:\n",
    "\n",
    "1) Chunk documents by heading - containing only the content from each subheading\n",
    "\n",
    "2) Embed each document\n",
    "\n",
    "3) Use Cosine similarity to retrieve documents in order to answer query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Anthropic documentation segments into a dictionary\n",
    "with open('data/anthropic_docs.json', 'r') as f:\n",
    "    anthropic_docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anthropic_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abbreviated_docs = anthropic_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_link': 'https://docs.anthropic.com/en/docs/welcome#get-started',\n",
       "  'chunk_heading': 'Get started',\n",
       "  'text': 'Get started\\n\\n\\nIf you’re new to Claude, start here to learn the essentials and make your first API call.\\nIntro to ClaudeExplore Claude’s capabilities and development flow.QuickstartLearn how to make your first API call in minutes.Prompt LibraryExplore example prompts for inspiration.\\nIntro to ClaudeExplore Claude’s capabilities and development flow.\\n\\nIntro to Claude\\nExplore Claude’s capabilities and development flow.\\nQuickstartLearn how to make your first API call in minutes.\\n\\nQuickstart\\nLearn how to make your first API call in minutes.\\nPrompt LibraryExplore example prompts for inspiration.\\n\\nPrompt Library\\nExplore example prompts for inspiration.\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/docs/welcome#models',\n",
       "  'chunk_heading': 'Models',\n",
       "  'text': 'Models\\n\\n\\nClaude consists of a family of large language models that enable you to balance intelligence, speed, and cost.\\n\\n\\n\\n\\n\\nCompare our state-of-the-art models.\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/docs/welcome#develop-with-claude',\n",
       "  'chunk_heading': 'Develop with Claude',\n",
       "  'text': 'Develop with Claude\\n\\n\\nAnthropic has best-in-class developer tools to build scalable applications with Claude.\\nDeveloper ConsoleEnjoy easier, more powerful prompting in your browser with the Workbench and prompt generator tool.API ReferenceExplore, implement, and scale with the Anthropic API and SDKs.Anthropic CookbookLearn with interactive Jupyter notebooks that demonstrate uploading PDFs, embeddings, and more.\\nDeveloper ConsoleEnjoy easier, more powerful prompting in your browser with the Workbench and prompt generator tool.\\n\\nDeveloper Console\\nEnjoy easier, more powerful prompting in your browser with the Workbench and prompt generator tool.\\nAPI ReferenceExplore, implement, and scale with the Anthropic API and SDKs.\\n\\nAPI Reference\\nExplore, implement, and scale with the Anthropic API and SDKs.\\nAnthropic CookbookLearn with interactive Jupyter notebooks that demonstrate uploading PDFs, embeddings, and more.\\n\\nAnthropic Cookbook\\nLearn with interactive Jupyter notebooks that demonstrate uploading PDFs, embeddings, and more.\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/docs/welcome#key-capabilities',\n",
       "  'chunk_heading': 'Key capabilities',\n",
       "  'text': 'Key capabilities\\n\\n\\nClaude can assist with many tasks that involve text, code, and images.\\nText and code generationSummarize text, answer questions, extract data, translate text, and explain and generate code.VisionProcess and analyze visual input and generate text and code from images.\\nText and code generationSummarize text, answer questions, extract data, translate text, and explain and generate code.\\n\\nText and code generation\\nSummarize text, answer questions, extract data, translate text, and explain and generate code.\\nVisionProcess and analyze visual input and generate text and code from images.\\n\\nVision\\nProcess and analyze visual input and generate text and code from images.\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/docs/welcome#support',\n",
       "  'chunk_heading': 'Support',\n",
       "  'text': 'Support\\n\\n\\nHelp CenterFind answers to frequently asked account and billing questions.Service StatusCheck the status of Anthropic services.\\nHelp CenterFind answers to frequently asked account and billing questions.\\n\\nHelp Center\\nFind answers to frequently asked account and billing questions.\\nService StatusCheck the status of Anthropic services.\\n\\nService Status\\nCheck the status of Anthropic services.\\nQuickstartxlinkedin\\nQuickstart\\nxlinkedin\\nGet started Models Develop with Claude Key capabilities Support\\nGet startedModelsDevelop with ClaudeKey capabilitiesSupport\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/api/#accessing-the-api',\n",
       "  'chunk_heading': 'Accessing the API',\n",
       "  'text': 'Accessing the API\\n\\n\\nThe API is made available via our web Console. You can use the Workbench to try out the API in the browser and then generate API keys in Account Settings.\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/api/#authentication',\n",
       "  'chunk_heading': 'Authentication',\n",
       "  'text': 'Authentication\\n\\n\\nAll requests to the Anthropic API must include an x-api-key header with your API key. If you are using the Client SDKs, you will set the API when constructing a client, and then the SDK will send the header on your behalf with every request. If integrating directly with the API, you’ll need to send this header yourself.\\nShellcurl https://api.anthropic.com/v1/messages --header \"x-api-key: YOUR_API_KEY\" ...\\nShell\\nShell\\n\\ncurl https://api.anthropic.com/v1/messages --header \"x-api-key: YOUR_API_KEY\" ...\\ncurl https://api.anthropic.com/v1/messages --header \"x-api-key: YOUR_API_KEY\" ...\\n```\\ncurl https://api.anthropic.com/v1/messages --header \"x-api-key: YOUR_API_KEY\" ...\\n\\n```\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/api/#content-types',\n",
       "  'chunk_heading': 'Content types',\n",
       "  'text': 'Content types\\n\\n\\nThe Anthropic API always accepts JSON in request bodies and returns JSON in response bodies. You will need to send the content-type: application/json header in requests. If you are using the Client SDKs, this will be taken care of automatically.\\nIP addressesxlinkedin\\nIP addresses\\nxlinkedin\\nAccessing the API Authentication Content types\\nAccessing the APIAuthenticationContent types\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/docs/quickstart#prerequisites',\n",
       "  'chunk_heading': 'Prerequisites',\n",
       "  'text': 'Prerequisites\\n\\n\\nTo complete this quickstart, you need:\\nAn Anthropic Console account\\nAn API key\\nPython 3.7+ or TypeScript 4.5+\\nAnthropic provides Python and TypeScript SDKs, although you can make direct HTTP requests to the API.\\n'},\n",
       " {'chunk_link': 'https://docs.anthropic.com/en/docs/quickstart#start-with-the-workbench',\n",
       "  'chunk_heading': 'Start with the Workbench',\n",
       "  'text': \"Start with the Workbench\\n\\n\\nAny API call you make–-regardless of the specific task-–sends a well-configured prompt to the Anthropic API. As you’re learning to make the most of Claude, we recommend that you start the development process in the Workbench, a web-based interface to Claude.\\nLog into the Anthropic Console and click Workbench.\\nIn the middle section, under User, let’s ask Claude a question.\\nUserWhy is the ocean salty?\\nUser\\nUser\\n\\nWhy is the ocean salty?\\nWhy is the ocean salty?\\n```\\nWhy is the ocean salty?\\n\\n```\\nClick Run. On the right side, you’ll see output like\\nResponseThe ocean is salty due to several factors:\\n\\n1. Weathering of rocks: Over millions of years, rain, rivers, and streams have eroded rocks containing mineral salts. These salts are carried into the ocean by water runoff.\\n2. Volcanic activity: Underwater volcanoes and hydrothermal vents release minerals, including salts, into the ocean water.\\n3. Atmospheric deposition: Salt particles from ocean spray can be carried by wind and deposited back into the ocean.\\n4. Evaporation: As water evaporates from the surface of the ocean, it leaves behind dissolved salts, increasing the concentration of salt in the remaining water.\\n5. Biological processes: Some marine organisms contribute to the ocean's salinity by releasing salt compounds as byproducts of their metabolism.\\n\\nOver time, these processes have continuously added salts to the ocean, while evaporation removes pure water, leading to the ocean's current salinity levels. It's important to note that the total amount of salt in the ocean remains relatively stable because the input of salts is balanced by the removal of salts through processes like the formation of evaporite deposits.\\nResponse\\nResponse\\n\\nThe ocean is salty due to several factors:\\n\\n1. Weathering of rocks: Over millions of years, rain, rivers, and streams have eroded rocks containing mineral salts. These salts are carried into the ocean by water runoff.\\n2. Volcanic activity: Underwater volcanoes and hydrothermal vents release minerals, including salts, into the ocean water.\\n3. Atmospheric deposition: Salt particles from ocean spray can be carried by wind and deposited back into the ocean.\\n4. Evaporation: As water evaporates from the surface of the ocean, it leaves behind dissolved salts, increasing the concentration of salt in the remaining water.\\n5. Biological processes: Some marine organisms contribute to the ocean's salinity by releasing salt compounds as byproducts of their metabolism.\\n\\nOver time, these processes have continuously added salts to the ocean, while evaporation removes pure water, leading to the ocean's current salinity levels. It's important to note that the total amount of salt in the ocean remains relatively stable because the input of salts is balanced by the removal of salts through processes like the formation of evaporite deposits.\\nThe ocean is salty due to several factors:\\n\\n1. Weathering of rocks: Over millions of years, rain, rivers, and streams have eroded rocks containing mineral salts. These salts are carried into the ocean by water runoff.\\n2. Volcanic activity: Underwater volcanoes and hydrothermal vents release minerals, including salts, into the ocean water.\\n3. Atmospheric deposition: Salt particles from ocean spray can be carried by wind and deposited back into the ocean.\\n4. Evaporation: As water evaporates from the surface of the ocean, it leaves behind dissolved salts, increasing the concentration of salt in the remaining water.\\n5. Biological processes: Some marine organisms contribute to the ocean's salinity by releasing salt compounds as byproducts of their metabolism.\\n\\nOver time, these processes have continuously added salts to the ocean, while evaporation removes pure water, leading to the ocean's current salinity levels. It's important to note that the total amount of salt in the ocean remains relatively stable because the input of salts is balanced by the removal of salts through processes like the formation of evaporite deposits.\\n```\\nThe ocean is salty due to several factors:\\n\\n1. Weathering of rocks: Over millions of years, rain, rivers, and streams have eroded rocks containing mineral salts. These salts are carried into the ocean by water runoff.\\n2. Volcanic activity: Underwater volcanoes and hydrothermal vents release minerals, including salts, into the ocean water.\\n3. Atmospheric deposition: Salt particles from ocean spray can be carried by wind and deposited back into the ocean.\\n4. Evaporation: As water evaporates from the surface of the ocean, it leaves behind dissolved salts, increasing the concentration of salt in the remaining water.\\n5. Biological processes: Some marine organisms contribute to the ocean's salinity by releasing salt compounds as byproducts of their metabolism.\\n\\nOver time, these processes have continuously added salts to the ocean, while evaporation removes pure water, leading to the ocean's current salinity levels. It's important to note that the total amount of salt in the ocean remains relatively stable because the input of salts is balanced by the removal of salts through processes like the formation of evaporite deposits.\\n\\n```\\nThis is a good answer, but let’s say we wanted to control the exact type of answer Claude gives. For example, only allowing Claude to respond to questions with poems. We can control the format, tone, and personality of the response by adding a System Prompt.\\nSystem promptYou are a world-class poet. Respond only with short poems.\\nSystem prompt\\nSystem prompt\\n\\nYou are a world-class poet. Respond only with short poems.\\nYou are a world-class poet. Respond only with short poems.\\n```\\nYou are a world-class poet. Respond only with short poems.\\n\\n```\\nClick Run again.\\nResponseThe ocean's salty brine,\\nA tale of time and elements combined.\\nRocks and rain, a slow erosion,\\nMinerals carried in solution.\\nEons pass, the salt remains,\\nIn the vast, eternal watery domain.\\nResponse\\nResponse\\n\\nThe ocean's salty brine,\\nA tale of time and elements combined.\\nRocks and rain, a slow erosion,\\nMinerals carried in solution.\\nEons pass, the salt remains,\\nIn the vast, eternal watery domain.\\nThe ocean's salty brine,\\nA tale of time and elements combined.\\nRocks and rain, a slow erosion,\\nMinerals carried in solution.\\nEons pass, the salt remains,\\nIn the vast, eternal watery domain.\\n```\\nThe ocean's salty brine,\\nA tale of time and elements combined.\\nRocks and rain, a slow erosion,\\nMinerals carried in solution.\\nEons pass, the salt remains,\\nIn the vast, eternal watery domain.\\n\\n```\\nSee how Claude’s response has changed? LLMs respond well to clear and direct instructions. You can put the role instructions in either the system prompt or the user message. We recommend testing to see which way yields the best results for your use case.\\nOnce you’ve tweaked the inputs such that you’re pleased with the output–-and have a good sense how to use Claude–-convert your Workbench into an integration.\\nClick Get Code to copy the generated code representing your Workbench session.\\nClick Get Code to copy the generated code representing your Workbench session.\\n\\nClick Get Code to copy the generated code representing your Workbench session.\\n\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbreviated_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vector database from disk.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the VectorDB\n",
    "db = VectorDB(\"anthropic_docs\")\n",
    "# Import the document segments into the vector database\n",
    "db.load_data(abbreviated_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a minimal LLM Facade class\n",
    "\n",
    "This facade makes it easy to use either AWS Bedrock or Anthropic Cloud for invoking the LLM.\n",
    "If a value for the anthropic_api_key is set, then Anthropic Cloud will be used, otherwise, AWS Bedrock is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM_MAX_TOKENS = 2500\n",
    "LLM_TEMPERATURE = 0.01\n",
    "BEDROCK_MODEL_ID = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "\n",
    "class LlmFacade:\n",
    "    def __init__(self, anthropic_api_key=None):\n",
    "        self.max_tokens = LLM_MAX_TOKENS\n",
    "        self.temperature = LLM_TEMPERATURE\n",
    "        # Use Anthropic Claude via Anthropic Cloud if the key is set\n",
    "        # if not, set up to use Anthropic Claude via Bedrock\n",
    "        self.aws_bedrock = True\n",
    "\n",
    "        if anthropic_api_key:\n",
    "            self.anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "            self.aws_bedrock = False\n",
    "            print(\"Configured to use: Anthropic Cloud Service\")\n",
    "        else:\n",
    "            session = boto3.Session()\n",
    "            region = session.region_name\n",
    "\n",
    "            # Set the model id to Claude Haiku\n",
    "            self.bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=region)\n",
    "            print(\"Configured to use: AWS Bedrock Service\")\n",
    "\n",
    "    def invoke(self, prompt: str) -> str:\n",
    "        if self.aws_bedrock == True:\n",
    "            return self.invoke_aws_bedrock_llm(prompt)\n",
    "        else:\n",
    "            return self.invoke_anthropic_cloud_llm(prompt)\n",
    "\n",
    "    def invoke_anthropic_cloud_llm(self, prompt: str) -> str:\n",
    "        messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "\n",
    "        response = self.anthropic_client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=self.max_tokens,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        return response.content[0].text\n",
    "\n",
    "    def invoke_aws_bedrock_llm(self, prompt: str) -> str:\n",
    "        messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "\n",
    "        inference_config = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"maxTokens\": self.max_tokens\n",
    "        }\n",
    "        converse_api_params = {\n",
    "            \"modelId\": BEDROCK_MODEL_ID,\n",
    "            \"messages\": messages,\n",
    "            \"inferenceConfig\": inference_config\n",
    "        }\n",
    "        # Send the request to the Bedrock service to generate a response\n",
    "        try:\n",
    "            response = self.bedrock_client.converse(**converse_api_params)\n",
    "\n",
    "            # Extract the generated text content from the response\n",
    "            text_content = response['output']['message']['content'][0]['text']\n",
    "\n",
    "            # Return the generated text content\n",
    "            return text_content\n",
    "\n",
    "        except ClientError as err:\n",
    "            message = err.response['Error']['Message']\n",
    "            print(f\"A client error occured: {message}\")\n",
    "        return(\"500: Request failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured to use: Anthropic Cloud Service\n"
     ]
    }
   ],
   "source": [
    "llm = LlmFacade(anthropic_api_key=anthropic_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The speed at which swallows fly can vary quite a bit, but here are some general details:\\n\\n- Common swallows (also known as barn swallows) typically fly at speeds between 12-24 mph (19-39 km/h) during normal flight.\\n\\n- When diving or chasing prey, swallows can reach top speeds of around 35-45 mph (56-72 km/h).\\n\\n- Migratory swallows can sustain flight speeds of 20-30 mph (32-48 km/h) over long distances during their seasonal migrations.\\n\\n- Factors like wind conditions, the swallow's flight path, and whether it's hunting or just cruising can all affect its flight speed.\\n\\n- Smaller swallow species like the bank swallow or tree swallow tend to be on the lower end of the speed range, while larger swallows like the barn swallow can reach the higher end.\\n\\nSo in general, swallows are quite agile and fast flyers, capable of bursts of speed when needed, but maintaining more moderate cruising speeds during normal flight. Their aerial acrobatics and speed make them excellent insect hunters.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how fast does a swallow fly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_base(query, db, similarity_threshold=0.7):\n",
    "    results = db.search(query, k=3, similarity_threshold=similarity_threshold)\n",
    "    context = \"\"\n",
    "    for result in results:\n",
    "        chunk = result['metadata']\n",
    "        context += f\"\\n{chunk['text']}\\n\"\n",
    "    return results, context\n",
    "\n",
    "def answer_query_base(query, db, llm):\n",
    "    documents, context = retrieve_base(query, db)\n",
    "    prompt = f\"\"\"\n",
    "    You have been tasked with helping us to answer the following query: \n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "    You have access to the following documents which are meant to provide context as you answer the query:\n",
    "    <documents>\n",
    "    {context}\n",
    "    </documents>\n",
    "    Please remain faithful to the underlying context, and only deviate from it if you are 100% sure that you know the answer already. \n",
    "    Answer the question now, and avoid providing preamble such as 'Here is the answer', etc\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_question = [\"i have a billing question\", \"what capabilities are there\", \"who's cat is that\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: i have a billing question\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'chunk_link': 'https://docs.anthropic.com/en/docs/welcome#support',\n",
       "   'chunk_heading': 'Support',\n",
       "   'text': 'Support\\n\\n\\nHelp CenterFind answers to frequently asked account and billing questions.Service StatusCheck the status of Anthropic services.\\nHelp CenterFind answers to frequently asked account and billing questions.\\n\\nHelp Center\\nFind answers to frequently asked account and billing questions.\\nService StatusCheck the status of Anthropic services.\\n\\nService Status\\nCheck the status of Anthropic services.\\nQuickstartxlinkedin\\nQuickstart\\nxlinkedin\\nGet started Models Develop with Claude Key capabilities Support\\nGet startedModelsDevelop with ClaudeKey capabilitiesSupport\\n'},\n",
       "  'similarity': 0.7012104891700733}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "results, context = retrieve_base(example_question[i], db)\n",
    "print(\"Question:\", example_question[i])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what capabilities are there\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'chunk_link': 'https://docs.anthropic.com/en/docs/welcome#key-capabilities',\n",
       "   'chunk_heading': 'Key capabilities',\n",
       "   'text': 'Key capabilities\\n\\n\\nClaude can assist with many tasks that involve text, code, and images.\\nText and code generationSummarize text, answer questions, extract data, translate text, and explain and generate code.VisionProcess and analyze visual input and generate text and code from images.\\nText and code generationSummarize text, answer questions, extract data, translate text, and explain and generate code.\\n\\nText and code generation\\nSummarize text, answer questions, extract data, translate text, and explain and generate code.\\nVisionProcess and analyze visual input and generate text and code from images.\\n\\nVision\\nProcess and analyze visual input and generate text and code from images.\\n'},\n",
       "  'similarity': 0.7397239715695028}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "results, context = retrieve_base(example_question[i], db, 0.7)\n",
    "print(\"Question:\", example_question[i])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who's cat is that\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "results, context = retrieve_base(example_question[i], db, 0.7)\n",
    "print(\"Question:\", example_question[i])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: i have a billing question\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm afraid I don't have enough information to fully answer your billing question. The documents provided give some general information about Anthropic's support and service status, but do not contain specific details about billing. To get a more complete answer, I would need additional details about the specific billing issue you are facing. Please feel free to provide more details about your billing question, and I'll do my best to assist you.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "result = answer_query_base(example_question[i], db, llm)\n",
    "print(\"Question:\", example_question[i])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what capabilities are there\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The key capabilities of Claude include:\\n\\nText and code generation: Summarize text, answer questions, extract data, translate text, and explain and generate code.\\n\\nVision: Process and analyze visual input and generate text and code from images.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "result = answer_query_base(example_question[i], db, llm)\n",
    "print(\"Question:\", example_question[i])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who's cat is that\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unfortunately, without any documents provided, I do not have enough context to determine whose cat is being referred to in the query \"who\\'s cat is that\". I would need additional information or documents to be able to provide a reliable answer to this query.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "result = answer_query_base(example_question[i], db, llm)\n",
    "print(\"Question:\", example_question[i])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
